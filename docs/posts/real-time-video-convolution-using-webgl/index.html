<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" href=https://magamig.github.io/favicon.ico><link rel=stylesheet href=/css/style.min.css><title>Real-Time Video Convolution Using WebGL</title><script>!sessionStorage.getItem("_swa")&&document.referrer.indexOf(location.protocol+"//"+location.host)!==0&&fetch("https://counter.dev/track?"+new URLSearchParams({referrer:document.referrer,screen:screen.width+"x"+screen.height,user:"magamig",utcoffset:"1"})),sessionStorage.setItem("_swa","1")</script><meta name=google-site-verification content="oOj7T7YgBib7EQmE1PWwWTP1DmyTTUxA3yTfPPzVf5s"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.5/dist/katex.min.css integrity=sha384-L+Gq2Cso/Y2x8fX4wausgiZT8z0QPZz7OqPuz4YqAycQJyrJT9NRLpjFBD6zlOia crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.5/dist/katex.min.js integrity=sha384-z64WtjpyrKFsxox9eI4SI8eM9toXdoYeWb5Qh+8PO+eG54Bv9BZqf9xNhlcLf/sA crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.5/dist/contrib/auto-render.min.js integrity=sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})'></script></head><body><div class=container><header id=banner><h2><a href=https://magamig.github.io/>Miguel Magalhães</a></h2><nav><ul><li>»
<a href=/posts/ title=Posts>Posts</a></li><li><a href=/map/ title=Map>Map</a></li><li><a href=/beers/ title=Beers>Beers</a></li><li><a href=/about/ title=About>About</a></li></ul></nav></header><main id=content><article><header id=post-header><h1>Real-Time Video Convolution Using WebGL</h1><time>May 3, 2021
· France</time></header><p>A <strong>convolution</strong> is a mathematical operation that is done by multiplying a pixel’s and its neighboring pixels
color value by a weighted matrix, and then adding those values together (for all the pixels of an image). The small matrix that defines the weights of the multiplication is called <strong>kernel</strong> or convolution matrix. This is used to apply effects to an image such as blurring, sharpening, outlining, and more; where each effect uses a distinct kernel.</p><p>The aforementioned technique is also used in the field of deep learning with <strong>convolutional neural networks (CNNs)</strong>. In this context, we try to learn the weights for each element of the convolution matrix in order to improve the score of our model. However, this post is more focused on just understanding how convolutions work.</p><p>A convolution can be defined by the following formula: <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></p><p>$$ g(x, y)=\omega * f(x, y)=\sum_{d x=-a}^{a} \sum_{d y=-b}^{b} \omega(d x, d y) f(x+d x, y+d y) $$</p><p>where $g(x,y)$ is the output filtered image, $f(x, y)$ is the input image and $\omega$ is the kernel. This is pictured in the following animation: <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p><video autoplay loop muted playsinline class=center>
<source src=/video/2d_convolution_animation.mp4 type=video/mp4>Your browser doesn't support this embedded video.</video><p>For something more interactive, I highly recommend you to visit &ldquo;<a href=https://setosa.io/ev/image-kernels/ target=_blank>Image Kernels</a>&rdquo; by Victor Powell. There are several examples that already display the process of performing convolutions, so I&rsquo;m bringing a different approach where we <strong>apply the kernels in real-time to a video feed using WebGL</strong>.</p><hr><p>In this approach we will be using WebGL - a rasterization engine that draws points, lines, and triangles based on code we supply. To compute what an image will look like and where it is placed, we need to write a program formed by two different functions. These functions are called <a href=https://en.wikipedia.org/wiki/Shader target=_blank>shaders</a>:</p><ul><li><strong>Vertex Shader</strong>, responsible for the positions</li><li><strong>Fragment Shader</strong>, responsible for the colors</li></ul><p>But for more material on this topic, visit &ldquo;<a href=https://webgl2fundamentals.org/ target=_blank>WebGL2 Fundamentals</a>&rdquo;. Since we want to compute the pixel&rsquo;s new color, we need to implement our logic within the fragment shader. Therefore, all that we do is <em>&ldquo;translate&rdquo;</em> the previous math formula into code as such:</p><pre id=fragment_shader>
precision mediump float;
uniform sampler2D image;
uniform vec2 resolution;
uniform mat3 kernel;
varying vec2 uv;

void main(){
    vec2 cellSize = 1.0 / resolution;
    for(int i=-1; i<=1; i++){
        for(int j=-1; j<=1; j++){
            vec2 vec = cellSize * vec2(float(i), float(j));
            gl_FragColor += 
                texture2D(image, uv + vec) *
                kernel[i][j];
        }
    }
    gl_FragColor[3] = 1.0; //alpha correction
}
</pre><p>In this example, we have the particularity of the <code>vec2 uv</code> variable which represents the current pixel cooordinates, and the <code>vec2 cellSize</code> which is the size of each pixel both horizontally and vertically.</p><p>Afterwards, we just need to perform this computation for each frame from the video feed - and there you have it: <strong>a real-time convolution over a video using WebGL</strong>. For more details on how this is working under the hood, you can check the page source code.</p><h2 id=visualization>Visualization</h2><video src=https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4 crossorigin=anonymous controls width=100% id=video muted autoplay>
Your browser does not support the video tag.</video><br><canvas id=canvas width=500 height=300></canvas><br><div class=row><b>Test a different kernel:</b><br><form name=kernelform class=col><input type=radio name=kernel value=[0,0,0,0,1,0,0,0,0]> Identity</input><br><input type=radio name=kernel value=[1,1,1,1,-8,-1,1,1,1] checked> Laplacian Edge Detection</input><br><input type=radio name=kernel value=[0.0625,0.125,0.0625,0.125,0.250,0.125,0.0625,0.125,0.0625]> Gaussian Blur</input><br><input type=radio name=kernel value=[0.111,0.111,0.111,0.111,0.111,0.111,0.111,0.111,0.111]> Box Blur</input><br><input type=radio name=kernel value=[0,-1,0,-1,5,-1,0,-1,0]> Sharpen</input><br><input type=radio name=kernel value=[-1,-1,-1,-1,9,-1,-1,-1,-1]> Unsharpen</input><br></form><table id=kernelviz class="matrix col"><tr><td>1</td><td>1</td><td>1</td></tr><tr><td>1</td><td>-8</td><td>1</td></tr><tr><td>1</td><td>1</td><td>1</td></tr></table></div><script>const canvas=document.getElementById("canvas"),video=document.getElementById("video"),kernelform=document.forms.kernelform,kernelviz=document.getElementById("kernelviz"),chunk=(e,t)=>Array.from({length:Math.ceil(e.length/t)},(n,s)=>e.slice(s*t,s*t+t));document.addEventListener("input",function(e){if(e.target.getAttribute("name")=="kernel"){let t=eval(e.target.value);t=t.map(e=>"<td>"+e+"</td>"),t=chunk(t,3),t=t.map(e=>"<tr>"+e.join("")+"</tr>").join(""),kernelviz.innerHTML=t}}),video.oncanplay=function(){canvasResize(),loadShaders()};function canvasResize(){let e=getComputedStyle(video);canvas.width=parseFloat(e.width),canvas.height=parseFloat(e.height)}function loadShaders(){let e=null,l={antialias:!1};for(let t=0;t<4;t++)if(e=canvas.getContext(["webgl","experimental-webgl","moz-webgl","webkit-3d"][t],l),e)break;let n=e.createShader(e.VERTEX_SHADER);e.shaderSource(n,`
            attribute vec2 vx;
            varying vec2 uv;
            
            void main(){
                gl_Position = vec4(vx.x*2.0-1.0, 1.0-vx.y*2.0, 0, 1);
                uv = vx;
            }
        `),e.compileShader(n);let s=e.createShader(e.FRAGMENT_SHADER);e.shaderSource(s,document.getElementById("fragment_shader").innerText),e.compileShader(s);let t=e.createProgram();e.attachShader(t,n),e.attachShader(t,s),e.linkProgram(t),e.useProgram(t);let o=e.getAttribLocation(t,"vx");e.enableVertexAttribArray(o);let i=e.createBuffer();e.bindBuffer(e.ARRAY_BUFFER,i),e.bufferData(e.ARRAY_BUFFER,new Float32Array([0,0,1,0,1,1,0,1]),e.STATIC_DRAW);let a=e.createBuffer();e.bindBuffer(e.ELEMENT_ARRAY_BUFFER,a),e.bufferData(e.ELEMENT_ARRAY_BUFFER,new Uint16Array([0,1,2,0,2,3]),e.STATIC_DRAW);let r=e.createTexture();e.bindTexture(e.TEXTURE_2D,r),e.texParameteri(e.TEXTURE_2D,e.TEXTURE_WRAP_T,e.CLAMP_TO_EDGE),e.texParameteri(e.TEXTURE_2D,e.TEXTURE_WRAP_S,e.CLAMP_TO_EDGE),e.texParameteri(e.TEXTURE_2D,e.TEXTURE_MAG_FILTER,e.LINEAR),e.texParameteri(e.TEXTURE_2D,e.TEXTURE_MIN_FILTER,e.LINEAR);let d=e.getUniformLocation(t,"resolution");e.uniform2fv(d,[canvas.width,canvas.height]);let u=e.getUniformLocation(t,"kernel");function c(){let t=kernelform.querySelector("input[name=kernel]:checked").value;e.uniformMatrix3fv(u,!1,eval(t)),e.clear(e.COLOR_BUFFER_BIT),e.activeTexture(e.TEXTURE0),e.bindTexture(e.TEXTURE_2D,r),e.texImage2D(e.TEXTURE_2D,0,e.RGB,e.RGB,e.UNSIGNED_BYTE,video),e.bindBuffer(e.ARRAY_BUFFER,i),e.vertexAttribPointer(o,2,e.FLOAT,!1,0,0),e.bindBuffer(e.ELEMENT_ARRAY_BUFFER,a),e.drawElements(e.TRIANGLES,6,e.UNSIGNED_SHORT,0),window.requestAnimationFrame(c)}c()}</script><style>.row{margin:20px 0}.col{vertical-align:middle;display:inline-block;margin:10px}.matrix{display:inline-block;position:relative;margin:30px}.matrix:before,.matrix:after{content:"";position:absolute;top:0;border:1px solid #000;width:6px;height:100%}.matrix:before{left:-6px;border-right:0}.matrix:after{right:-6px;border-left:0}.matrix td{padding:5px 15px;text-align:center}video::-webkit-media-controls-fullscreen-button{display:none}</style><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Song Ho Ahn (안성호). <a href=http://www.songho.ca/dsp/convolution/convolution.html#convolution_2d target=_blank>Convolution</a>. Digital Signal Processing.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Michael Plotke. <a href=https://commons.wikimedia.org/wiki/File:2D_Convolution_Animation.gif target=_blank>2D Convolution Animation</a>. Wikimedia Commons.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></article></main><footer id=footer></footer><div></body></html>